<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prashant Subedi - Portfolio</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>Prashant Subedi</h1>
        <nav>
            <ul>
                <li><a href="https://medium.com/@subedi09">Blog</a></li>
                <li><a href="#portfolio">Portfolio</a></li>
                <li><a href="cv.pdf" target="_blank">View CV</a></li> 
            </ul>
        </nav>
    </header>

    <section id="about">
        <div class="about-content">
            <img src="photo.JPG" alt="Prashant Subedi" class="profile-photo" id="profile-photo">
            <h2>About Me</h2>
            <p>Hi, I am Prashant Subedi: A passionate programmer specializing in Flutter, with expertise in .NET, Android, HTML/CSS, Java, and more. Dedicated to crafting innovative solutions and continuous learning.</p>
        </div>
    </section>
   

    <section id="portfolio">
        <h2>Portfolio</h2>
        <div class="portfolio-item">
            <img  src="hgcv.png" alt="Hand Gesture Controlled Virtual Mouse">
            <div class="project-info">
              <a href="https://github.com/prashant0010010/Hand-Gesture-Controlled-Virtual-Mouse-FinalYearProject.git">  <h3>Hand Gesture Controlled Virtual Mouse</h3></a>
              <p>Gesture Controlled Virtual Mouse makes human computer interaction simple by making use of Hand Gestures and Voice Commands. The computer requires almost no direct contact. All i/o operations can be virtually controlled by using static and dynamic hand gestures along with a voice assistant. This project makes use of the state-of-art Machine Learning and Computer Vision algorithms to recognize hand gestures and voice commands, which works smoothly without any additional hardware requirements. It leverages models such as CNN implemented by MediaPipe running on top of pybind11. It consists of two modules: One which works direct on hands by making use of MediaPipe Hand detection, and other which makes use of Gloves of any uniform color. Currently it works on Windows platform.</p>
            </div>
        </div>
        <!-- <div class="portfolio-item">
            <img src="portfolio-image2.jpg" alt="Portfolio Item 2">
            <div class="project-info">
                <h3>Project Title 2</h3>
                <p>Gesture Controlled Virtual Mouse makes human computer interaction simple by making use of Hand Gestures and Voice Commands. The computer requires almost no direct contact. All i/o operations can be virtually controlled by using static and dynamic hand gestures along with a voice assistant. This project makes use of the state-of-art Machine Learning and Computer Vision algorithms to recognize hand gestures and voice commands, which works smoothly without any additional hardware requirements. It leverages models such as CNN implemented by MediaPipe running on top of pybind11. It consists of two modules: One which works direct on hands by making use of MediaPipe Hand detection, and other which makes use of Gloves of any uniform color. Currently it works on Windows platform.</p>
            </div>
        </div> -->
    </section>

    <footer>
        <p>&copy; 2024 Prashant Subedi. All rights reserved.</p>
    </footer>

    <script src="script.js"></script>  
</body>
</html>
